{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit==1.23.1 (from -r requirements.txt (line 1))\n",
      "  Using cached streamlit-1.23.1-py2.py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: python-dotenv==1.0.0 in c:\\app\\.venv\\lib\\site-packages (from -r requirements.txt (line 2)) (1.0.0)\n",
      "Requirement already satisfied: ollama==0.4.6 in c:\\app\\.venv\\lib\\site-packages (from -r requirements.txt (line 3)) (0.4.6)\n",
      "Requirement already satisfied: httpx==0.27.2 in c:\\app\\.venv\\lib\\site-packages (from -r requirements.txt (line 4)) (0.27.2)\n",
      "Requirement already satisfied: pydantic==2.10.5 in c:\\app\\.venv\\lib\\site-packages (from -r requirements.txt (line 5)) (2.10.5)\n",
      "Requirement already satisfied: anyio==4.8.0 in c:\\app\\.venv\\lib\\site-packages (from -r requirements.txt (line 6)) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.0.7 in c:\\app\\.venv\\lib\\site-packages (from -r requirements.txt (line 7)) (1.0.7)\n",
      "Requirement already satisfied: certifi==2024.12.14 in c:\\app\\.venv\\lib\\site-packages (from -r requirements.txt (line 8)) (2024.12.14)\n",
      "Requirement already satisfied: sniffio==1.3.1 in c:\\app\\.venv\\lib\\site-packages (from -r requirements.txt (line 9)) (1.3.1)\n",
      "Requirement already satisfied: h11==0.14.0 in c:\\app\\.venv\\lib\\site-packages (from -r requirements.txt (line 10)) (0.14.0)\n",
      "Requirement already satisfied: annotated-types==0.7.0 in c:\\app\\.venv\\lib\\site-packages (from -r requirements.txt (line 11)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\app\\.venv\\lib\\site-packages (from -r requirements.txt (line 12)) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions==4.12.2 in c:\\app\\.venv\\lib\\site-packages (from -r requirements.txt (line 13)) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup==1.2.2 in c:\\app\\.venv\\lib\\site-packages (from -r requirements.txt (line 14)) (1.2.2)\n",
      "Collecting langchain==0.0.240 (from -r requirements.txt (line 15))\n",
      "  Using cached langchain-0.0.240-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langchain-community==0.0.10 (from -r requirements.txt (line 16))\n",
      "  Using cached langchain_community-0.0.10-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting langchain-huggingface==0.0.3 (from -r requirements.txt (line 17))\n",
      "  Using cached langchain_huggingface-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Ignored the following versions that require a different python version: 0.55.2 Requires-Python <3.5\n",
      "ERROR: Could not find a version that satisfies the requirement langchain-groq==0.0.5 (from versions: 0.0.1, 0.1.0, 0.1.1, 0.1.2, 0.1.3, 0.1.4, 0.1.5, 0.1.6, 0.1.8, 0.1.9, 0.1.10, 0.2.0.dev0, 0.2.0.dev1, 0.2.0, 0.2.1, 0.2.2, 0.2.3)\n",
      "ERROR: No matching distribution found for langchain-groq==0.0.5\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pdfminer.high_level import extract_text\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain.document_loaders import JSONLoader\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain import hub\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import re\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    model=\"llama3-8b-8192\",\n",
    "    temperature=0, \n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    given the information {information} about a person I want you to create:\n",
    "    1. A short summary\n",
    "    2. two interesting facts about them\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"information\"],\n",
    "    template=query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_data =\"\"\"\n",
    "Geoffrey Everest Hinton (born 6 December 1947) is a British-Canadian computer scientist, cognitive scientist, \n",
    "cognitive psychologist, known for his work on artificial neural networks which earned him the title as the \n",
    "\"Godfather of AI\". Hinton is University Professor Emeritus at the University of Toronto. From 2013 to 2023, \n",
    "he divided his time working for Google (Google Brain) and the University of Toronto, before publicly announcing \n",
    "his departure from Google in May 2023, citing concerns about the risks of artificial intelligence (AI) technology.\n",
    "In 2017, he co-founded and became the chief scientific advisor of the Vector Institute in Toronto.\n",
    "\n",
    "With David Rumelhart and Ronald J. Williams, Hinton was co-author of a highly cited paper published in 1986 \n",
    "that popularised the backpropagation algorithm for training multi-layer neural networks, although they were \n",
    "not the first to propose the approach. Hinton is viewed as a leading figure in the deep learning community.\n",
    "The image-recognition milestone of the AlexNet designed in collaboration with his students Alex Krizhevsky \n",
    "and Ilya Sutskever for the ImageNet challenge 2012[22] was a breakthrough in the field of computer vision.\n",
    "\n",
    "Hinton received the 2018 Turing Award, often referred to as the \"Nobel Prize of Computing\", together with \n",
    "Yoshua Bengio and Yann LeCun, for their work on deep learning. They are sometimes referred to as the \n",
    "\"Godfathers of Deep Learning\", and have continued to give public talks together. He was also awarded \n",
    "the 2024 Nobel Prize in Physics, shared with John Hopfield.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chain.invoke(input={\"information\": text_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the information about Geoffrey Everest Hinton:\n",
      "\n",
      "**Summary:** Geoffrey Everest Hinton is a British-Canadian computer scientist, cognitive scientist, and cognitive psychologist known for his work on artificial neural networks and deep learning. He is often referred to as the \"Godfather of AI\" and has made significant contributions to the field of computer vision and machine learning.\n",
      "\n",
      "**Interesting Facts:**\n",
      "\n",
      "1. **Co-author of a highly cited paper:** Hinton co-authored a paper with David Rumelhart and Ronald J. Williams in 1986 that popularized the backpropagation algorithm for training multi-layer neural networks. This paper has had a significant impact on the field of artificial intelligence.\n",
      "2. **Recipient of prestigious awards:** Hinton has received several prestigious awards, including the 2018 Turing Award, often referred to as the \"Nobel Prize of Computing\", and the 2024 Nobel Prize in Physics, shared with John Hopfield. He is also known as the \"Godfather of AI\" and has been recognized as a leading figure in the deep learning community.\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jq in c:\\app\\.venv\\lib\\site-packages (1.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install jq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_data(base_path):\n",
    "    \"\"\"\n",
    "    This function loads text data from JSON files organized by topic\n",
    "    in multiple folders under the specified base path.\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    for topic in os.listdir(base_path):\n",
    "        topic_path = os.path.join(base_path, topic)\n",
    "        if os.path.isdir(topic_path):\n",
    "            for filename in os.listdir(topic_path):\n",
    "                if filename.endswith(\".json\"):\n",
    "                    file_path = os.path.join(topic_path, filename)\n",
    "                    loader = JSONLoader(file_path=file_path, jq_schema=\".text\")  # Use \".text\"\n",
    "                    documents.extend(loader.load())\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "react_docs = load_json_data(base_path=\"data/processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCOUNTANT\n",
      "Summary\n",
      "\n",
      "Financial Accountant specializing in financial planning, reporting and analysis within the Department of Defense.\n",
      "\n",
      "Highlights\n",
      "\n",
      "Account reconciliations\n",
      "Results-oriented\n",
      "Financial reporting\n",
      "Critical thinking\n",
      "\n",
      "Accomplishments\n",
      "\n",
      "Accounting operations professional\n",
      "Analysis of financial systems\n",
      "ERP (Enterprise Resource Planning) software.\n",
      "Excellent facilitator\n",
      "\n",
      "Served on a tiger team which identified and resolved General Ledger postings in DEAMS totaling $360B in accounting adjustments. This allowed\n",
      "for the first successful fiscal year-end close for 2012.\n",
      "\n",
      "In collaboration with DFAS Europe, developed an automated tool that identified duplicate obligations. This tool allowed HQ USAFE to\n",
      "deobligate over $5M in duplicate obligations.\n",
      "\n",
      "Experience\n",
      "Company Name July 2011 to November 2012 Accountant \n",
      "City , State\n",
      "\n",
      "Enterprise Resource Planning Office (ERO)\n",
      "\n",
      "In this position as an Accountant assigned to the Defense Enterprise Accounting and Management System (DEAMS) ERO I was\n",
      "responsible for identifying and resolving issues affecting the DEAMS General Ledger.\n",
      "I worked with teammates from the Procure to Pay, Orders to Cash, and Budget to Report areas to resolve daily challenges encountered\n",
      "with the deployment of DEAMS to additional customers and when system change requests were promoted to production.\n",
      "I supported the testing of scripts, patches, and system change requests ensuring any anomalies were identified to the DEAMS Functional\n",
      "Management Office for action by the DEAMS Program Management Office and/or the System Integrator.\n",
      "In addition, I served on a tiger team designed to identify and resolve General Ledger posting differences and supported the development of\n",
      "$360B in accounting adjustments allowing for the first successful fiscal year-end close in 2012.\n",
      "These actions also allowed for the reconciliation and closure of fiscal year 2010 and 2011 accounting adjustments ensuring that all DEAMS\n",
      "fiscal year-end requirements were completed.\n",
      "These actions were recognized as critical to the successful review report issued by the Air Force Operational Test and Evaluation Center\n",
      "(AFOTEC) resulting in the Air Force receiving the authority to continue with the deployment of DEAMS.\n",
      "\n",
      "Company Name April 2010 to June 2011 Resource Advisor \n",
      "City , State\n",
      "\n",
      "In this position as Resource Advisor for the 1st Air Communications Operation Squadron (1ACOS) I was responsible for providing\n",
      "financial advice and decision support to the Commander.\n",
      "I was responsible for coordinating a $4.6M budget between four funding sources.\n",
      "I coordinated with USAFE Directorate of Intelligence (USAFE/A2), USAFE Directorate of Air and Space Operations (USAFE/A3),\n",
      "USAFE Directorate of Communications (USAFE/A6) and the 435th Air Ground Operations Wing to ensure 1ACOS meets its mission\n",
      "requirements.\n",
      "I consistently managed three separate timelines for providing budget/unfunded requirements, providing documentation and various reports in\n",
      "the required format for each organization.\n",
      "I discussed the outcome of the Group and Directorate budget meetings providing feedback the same day to the Flight Chiefs and CC any\n",
      "issue which affects 1ACOS directly.\n",
      "I monitored the Defense Travel System (DTS) daily and identify orders and authorizations needing approval and provided notification to the\n",
      "appropriate Reviewing Officials and Approvers.\n",
      "Utilizing DTS and the General Accounting and Finance System I reviewed status reports to identify anomalies in obligations and have\n",
      "identified those orders which require correction prior to payment.\n",
      "I provided Government Purchase Card (GPC) status reports the same day they are requested and in addition, communicated with the\n",
      "appropriate cardholders when changes were required to support their program.\n",
      "I identified cardholder training requirements and monitored these requirements to ensure all required training was completed in support of\n",
      "this mission critical program.\n",
      "I developed guidance for the GPC cardholders on procedures for requesting training for the squadron and in addition I provided answers to\n",
      "cardholder questions on unique or non-standard issues/concerns.\n",
      "\n",
      "\fAssumed the role of the Billing Official during my final rating period and completed a self inspection of the program for the Management\n",
      "Control Program, zero findings.\n",
      "During yearly audit by 700th CONS received zero findings.\n",
      "\n",
      "Company Name July 2008 to April 2010 Staff Accountant \n",
      "City , State\n",
      "\n",
      "In my position as the Staff Accountant for HQ USAFE I was responsible for providing accounting and financial oversight and advice to\n",
      "customers throughout the Command in support of the USAFE Comptroller.\n",
      "I was responsible for performing ongoing analysis of financial programs to identify negative trends and weaknesses, ensured specific\n",
      "weaknesses were corrected, and determined whether systemic or repeat issues were identified and adequately addressed.\n",
      "I was required to apply a comprehensive knowledge of analysis/reporting requirements and data produced to resolve these issues.\n",
      "In collaboration with DFAS Europe, developed an automated tool that identifies duplicate obligations by comparing records in the\n",
      "accounting system to the contracting system and provided notification to the funds manager for review and resolution.\n",
      "This tool eliminated hours of manual research and results allowed HQ USAFE to deobligate over $5M in duplicate obligations.\n",
      "I was responsible for establishing various performance metrics which ensured effective and efficient use of USAFE financial resources.\n",
      "I supported the USAFE/FMA Financial metrics program by collaborating with DFAS Limestone in the development of an automated tool\n",
      "that provided senior leaders with visibility to any USAFE unit that is not in compliance with the established rules and regulations related to\n",
      "the GPC.\n",
      "This tool provides management reports that are used to populate the monthly metric charts which are briefed by the USAFE/FMA.\n",
      "This tool provided the capability for USAFE/FMA to collaborate with USAFE Contracting and develop/deploy joint guidance that supports\n",
      "the established Air Force Instruction mandating card suspension for card holders who are not in compliance with required reservation of\n",
      "funds in the entitlement system in support of the GPC.\n",
      "I identified and resolved a problem with five GPC accounts that had been rejecting during the automated interface process each month.\n",
      "My research revealed that these accounts were rejecting for invalid paying station and required manual intervention by both Wing and\n",
      "DFAS personnel.\n",
      "This not only created rework, it delayed the payment of the invoices.\n",
      "I partnered with DFAS Denver, corrected the records in the Access On-Line accounts eliminating the error condition.\n",
      "I identified a method to deliver one-on-one training in support of the USAFE deployment of the Open Document Analysis (ODA) tool in\n",
      "FMSuite.\n",
      "By utilizing Defense Connect Online I provided training remotely, virtually eliminating the need to expend funds on Temporary Duty (TDY)\n",
      "travel.\n",
      "The results of this training produced results that went well above expectations and were noted by the ODA Program Management Office.\n",
      "\n",
      "Company Name January 2007 to July 2009 Chief, Reports Branch. Accounts Maintenance and Control \n",
      "City , State\n",
      "\n",
      "In my position as Chief of the Reports Branch in Accounts Maintenance & Control (AM&C) I was responsible for ensuring the\n",
      "development and standardization of various managerial and system reports.\n",
      "I was responsible for the completeness and accuracy of weekly, monthly, quarterly, semi-annual, and annual reports.\n",
      "My branch monitored errors in the General Accounting and Finance System (GAFS/BQ) and ensured corrective actions were\n",
      "accomplished.\n",
      "I also ensured fund balances were reconciled and reports were verified prior to release to base activities and higher headquarters.\n",
      "Limestone reorganized under the High Performing Organization (HPO) in January 2007 and at that time I was reassigned to AM&C, a\n",
      "Directorate which previously did not exist.\n",
      "My challenge during that time was to staff my branch, implement an aggressive training schedule, and ensure the continuity of financial\n",
      "reporting was maintained.\n",
      "As we transitioned into the HPO we continued defining the missions and functions for AM&C for the entire network.\n",
      "I participated in biweekly conference calls with Standards and Compliance in an effort to define missions and functions for AM&C.\n",
      "Worked with management in determining FTEs needed for the branch.\n",
      "I was responsible for developing meaningful performance standards for my employees since this branch and its functions did not previously\n",
      "exist.\n",
      "Limestone POC for an initiative to eliminate suspense accounts throughout the agency.\n",
      "Identified suspense accounts not initially targeted, formulated strategies to eliminate accounts or requested waivers, and participated in plans\n",
      "to modify processes using suspense accounts, such as the interfund suspense account.\n",
      "These actions provided initial progress towards meeting the Department of Treasury's mandate to discontinue suspense accounts by\n",
      "February 2009.\n",
      "Worked with staff to reduce reconciliations from $6.9 million in February 2007 to $1.1 million in August, accomplished this despite loss in\n",
      "experienced personnel and realigning resources to support critical initiatives in Accounts Payable.\n",
      "I orchestrated the transition of reporting requirements for the Transportation Financial Management System (TFMS) workload from DFAS\n",
      "Omaha to Limestone.\n",
      "After transition to Limestone encouraged staff responsible for these reports to streamline the processes.\n",
      "Staff automated a completely manual, time consuming process, thus eliminating potential key stroke errors and manually validating numerous\n",
      "spreadsheets and listings.\n",
      "Contributor to Federal Managers Financial Integrity Act (FMFIA) Compliance Review and establishment of assessable units.\n",
      "\n",
      "\fIdentified inconsistencies in information provided by staff on foreign currency fluctuation adjustments.\n",
      "Persisted in getting higher level review of regulatory and policy guidance.\n",
      "Report of foreign currency fluctuation is now consistently accurate.\n",
      "\n",
      "Company Name February 2000 to January 2007 Chief, Accounts Payable Branch \n",
      "City , State\n",
      "\n",
      "As Chief Of Accounts Payable I was responsible for the overall management of a branch consisting of over 120 employees.\n",
      "My four first line supervisors were responsible for establishing priorities, schedules, and work assignments ensuring changes in workload are\n",
      "accounted for to minimize the impact on normal office operations.\n",
      "We consistently reviewed these areas and made necessary personnel moves based on shifting priorities.\n",
      "This was extremely important during the DFAS Denver directed database consolidations and with the assumption of the Air National Guard\n",
      "workload.\n",
      "Workload increased rapidly while staffing increased gradually, which dictated frequent priority changes and personnel moves.\n",
      "I also worked closely with the Major Commands supported by DFAS Limestone strengthening our partnership when workload spikes\n",
      "negatively impacted our customers.\n",
      "In December 2004, our overaged invoice percentage was nearing 25% and we had a backlog of vendor pay documents exceeding 30,000.\n",
      "By working with the DFAS Command Client Executives and the Major Command Comptrollers, I was instrumental in forming a strategy\n",
      "that included soliciting Air Force personnel assistance in document processing, identification of \"must pay now\" bills, and the formation of\n",
      "special action response teams dedicated to responding to our customer's most urgent requirements.\n",
      "As a result of these efforts, in a three month period, we were able to reduce our overaged invoice percentage by 19% and our backlog of\n",
      "documents to no documents over 20 days old thereby minimizing the adverse impact on customer funds.\n",
      "I was responsible for providing personnel feedback sessions quarterly and prepared supervisory appraisals of employees' performance and\n",
      "potential for advancement.\n",
      "Partnering with the management staff and employees, I was instrumental in establishing Employee Performance Plans that linked employee\n",
      "performance to established DFAS Strategies and Balance Scorecard goals.\n",
      "In this position as a supervisory accountant I was responsible for performing ongoing analysis of the Vendor Pay workflow and production\n",
      "to identify negative trends and weaknesses, ensure specific weaknesses have been corrected, and determine whether systemic or repeat\n",
      "issues have been identified and adequately addressed.\n",
      "I was required to apply a comprehensive knowledge of analysis/reporting requirements, work processes, vendor pay system structures, and\n",
      "data produced to resolve these issues.\n",
      "Utilizing my expertise with Louis II data retrieval software, I produced ad-hoc data queries for in-house and external use by our customers.\n",
      "These retrievals were designed to reduce the man- hours necessary to perform complex finance and accounting functions by DFAS and Air\n",
      "Force personnel.\n",
      "I was responsible for the budget resources necessary to operate the branch.\n",
      "In this capacity, I prepared budget over execution justifications, plan and monitor overtime costs, and control supply purchases to ensure the\n",
      "most cost efficient operation possible.\n",
      "I was required to respond to inquiries from various sources, which include, but are not limited to, vendors, DFAS management, accounting\n",
      "liaison offices, resource advisors, and other DFAS field sites.\n",
      "These inquiries required my ability to relay technical aspects of systems deficiencies to customers who are not familiar with our operation.\n",
      "I participated in video teleconferences, conference calls, and briefings designed to address customer and DFAS management requirements.\n",
      "I was called upon to explain, in laymen's terms, DFAS policy and procedures with regards to delays in payment due to various reasons.\n",
      "I responded to various audit reports and studies; ensuring senior management and audit personnel, understand particular situations within the\n",
      "Vendor Pay business process that result in these findings.\n",
      "\n",
      "Company Name February 1999 to February 2000 Chief, Recon and Reports Branch \n",
      "City , State\n",
      "\n",
      "In my position as Chief, Vendor Pay Reports and Recon Branch, I exercised supervision (either directly or indirectly) over 22 employees\n",
      "primarily in the \"525\" series in grades ranging from GS-5 through GS-8.\n",
      "This responsibility also included supervision of the German local national workers assigned to my duty section.\n",
      "I was responsible for planning, directing, and supervising the activities of the work force in the review, interpretation, processing, and\n",
      "reconciliation of vendor pay and accounting data and the production of timely and accurate financial statement report requirements.\n",
      "I participated in the development of branch policies continually reviewing and evaluating the organizational operations, work distribution, and\n",
      "procedures.\n",
      "I coordinated the activities of the assigned functions with those of other organizations to obtain the most effective correlation of financial\n",
      "data.\n",
      "Directed and provided technical guidance to subordinates in the assigned area.\n",
      "Assured the timeliness and accuracy of assigned workload.\n",
      "Planned, organized, directed, coordinated, and reviewed the work of subordinate's sections ensuring the mission and functions of the\n",
      "division were carried out.\n",
      "I managed and realigned resources, conducted program analyses, and made decisions in accordance with unit cost principles, outputs,\n",
      "targets, and changing budgetary constraints.\n",
      "I participated in long range planning, goal setting, and evaluating the subordinate staff.\n",
      "Interpreted and clarified branch policies and resolved operational problems.\n",
      "Ensured efficient utilization and professional development of my staff.\n",
      "\n",
      "\fI was expected to provide reasonable assurance that operations were conducted in compliance with applicable laws and that funds,\n",
      "property, and other assets were safeguarded against waste, loss, unauthorized use, or misappropriation.\n",
      "I ensured continuing and affirmative application and support of DoD and DFAS policy concerning the equal opportunity and affirmative\n",
      "action programs.\n",
      "Ensured personnel management within organizational entity under my supervision was accomplished without regard to race, color, religion,\n",
      "sex, age, national origin, or handicap.\n",
      "I kept abreast of developments, policy issuance, and other similar material in the equal opportunity field and fully supported the DoD and\n",
      "DFAS Equal Opportunity Program.\n",
      "I was responsible and accountable for the safety and health of my subordinates.\n",
      "I ensured personnel were trained to work safely.\n",
      "I enforced safety and health rules, corrected unsafe or unhealthy acts and unsafe or unhealthy mechanical or physical conditions, investigated\n",
      "mishaps and tool other actions necessary to ensure the safety and health of my employees.\n",
      "\n",
      "Company Name June 1995 to February 1999 Chief, Accounts Payable Branch \n",
      "City , State\n",
      "\n",
      "I was responsible for establishing priorities, schedules, and work assignments ensuring changes in workload are accounted for to minimize\n",
      "the impact on normal office operations.\n",
      "This was important during the DFAS Denver directed workload realighment to the Field Sites servicing our customers by Major Command.\n",
      "Workload increased which dictated frequent priority changes and personnel moves.\n",
      "I also worked closely with the Major Commands supported by DFAS Limestone strengthening our partnership when workload spikes\n",
      "negatively impacted our customers.\n",
      "I was responsible for providing personnel feedback sessions quarterly and preparedsupervisory appraisals of employees' performance and\n",
      "potential for advancement.\n",
      "As a supervisory accountant I was responsible for performing ongoing analysis of the Vendor Pay workflow and production.\n",
      "I identified negative trends and weaknesses, ensured specific weaknesses were corrected, and determine whether systemic or repeat issues\n",
      "were identified and adequately addressed.\n",
      "I was required to apply a comprehensive knowledge of analysis/reporting requirements, work processes, vendor pay system structures, and\n",
      "data produced to resolve these issues.\n",
      "Utilizing my knowledge with Louis II data retrieval software, I produced ad-hoc data queries for in-house and external use by our\n",
      "customers.\n",
      "These retrievals are all designed to reduce the man- hours necessary to perform complex finance and accounting functions by DFAS and\n",
      "Air Force personnel.\n",
      "I was responsible for the budget resources necessary to operate the branch.\n",
      "In this capacity, I prepared budget over execution justifications, plan and monitor overtime costs, and control supply purchases to ensure the\n",
      "most cost efficient operation possible.\n",
      "I was required to respond to inquiries from various sources, which include, but are not limited to, vendors, DFAS management, accounting\n",
      "liaison offices, resource advisors, and other DFAS field sites.\n",
      "These inquiries require my ability to relay technical aspects of systems deficiencies to customers who are not familiar with our operation.\n",
      "I participated in video teleconferences, conference calls, and briefings designed to address customer and DFAS management requirements.\n",
      "I was often called upon to explain, in laymen's terms, DFAS policy and procedures with regards to delays in payment due to various\n",
      "reasons.\n",
      "I was required to respond to various audit reports and studies; ensuring senior management and audit personnel, understand particular\n",
      "situations within the Vendor Pay business process that result in these findings.\n",
      "I was hand selected by the Field Site Director and Vendor Pay Site Manager to represent DFAS Limestone on a team comprised of\n",
      "representatives from all DFAS Denver field sites to provide training to our Air Force base level Resource Advisors.\n",
      "During a five week period, I provided \"Boot Camp\" training to over 400 base level personnel ensuring resource advisors were familiar with\n",
      "the DFAS structure and mission requirements related to funds management.\n",
      "\n",
      "Company Name June 1994 to June 1995 Accountant, Network Assistant Team \n",
      "City , State\n",
      "\n",
      "As a member of the Network Assistance Team, I was required to have an extensive working knowledge of DoD accounting systems,\n",
      "theory, policy, and procedures.\n",
      "I was consistently called upon to develop and implement procedures consistent with DoD regulations.\n",
      "Coordinated with DFAS Denver and the Omaha Field Site on the consolidation of the first geographically separated Defense Accounting\n",
      "Office into DFAS.\n",
      "In my position as a member of the Network Assistance Team I was required, upon arrival at each base level Defense Accounting Office\n",
      "(DAO) to provide an in-brief.\n",
      "This briefing identified team members, the purpose of the visit, goals, and responsibilities.\n",
      "Upon completion of the assignment, provided a written and oral out-brief outlining the team accomplishments during the visit.\n",
      "I provided recommendations to preclude recurring problems and to prepare the organization for consolidation.\n",
      "\n",
      "Company Name June 1993 to June 1994 Supervisor, Accounts Control Branch \n",
      "City , State\n",
      "\n",
      "I directed/supervised the accomplishment of all financial reports and statements.\n",
      "\n",
      "\fI directed/supervised the accomplishment of all financial reports and statements.\n",
      "I was responsible for the completeness and accuracy of weekly, monthly, quarterly, semi-annual, and annual reports.\n",
      "Monitored errors in the General Accounting and Finance System (GAFS/BQ) and ensured corrective actions were accomplished.\n",
      "I also ensured fund balances were reconciled to the appropriate audit listings and verified reports prior to release to base activities and\n",
      "higher headquarters.\n",
      "I furnished accounting data to base organizations often interpreting and analyzing the data to help funds managers resolve problems and\n",
      "manage their programs more effectively.\n",
      "I attended Major Command (MAJCOM) and Headquarters level workshops to participate and contribute to accounting policy and system\n",
      "changes.\n",
      "I provided professional assistance to Data Automation relevant to processing of accounting and finance data, interpreting deficiencies in\n",
      "software based on output products and system related problems.\n",
      "I utilized my working knowledge of commercial and government accounting system principles and knowledge of Processing Centers (PCs)\n",
      "to review, verify, analyze, and evaluate accounting and finance operations.\n",
      "While serving as Chief, Account Control I ensured areas of concern were addressed, concentrating on problem areas related to the\n",
      "database.\n",
      "I analyzed computer output products to determine processing deficiencies.\n",
      "They included, but were not limited to, the Open Document Listing (ODL), Operating Budget Ledger (OBL), Allotment Ledger (AL), and\n",
      "the Accounting and Finance Workload Information Management System (A&F WIMS) Extract list.\n",
      "I provided technical assistance related to policy and procedural.\n",
      "changes required as a result of the impending base closure.\n",
      "Analyzed/developed and recommended improved training procedures enabling better use of system procedures ensuring governing\n",
      "directives were followed.\n",
      "I evaluated accuracy of accounting records prior to fiscal year closeout ensuring the Accounting and Finance Officer could certify their\n",
      "accuracy as required by regulation.\n",
      "Examined accounting transactions and documents to ensure they conformed to established accounting policy and principles.\n",
      "Coordinated and directed fiscal year end conversion for the GAFS and Integrated Accounts Payable System (IAPS).\n",
      "\n",
      "Education\n",
      "Northern Maine Community College 1994 Associate : Accounting City , State , USA\n",
      "\n",
      "Emphasis in Business\n",
      "\n",
      "1994 Associates : Accounting City , State , USA GPA: GPA: 3.41\n",
      "\n",
      "Accounting GPA: 3.41 174 Hours, Quarter\n",
      "\n",
      "Attended Husson College, major Accounting 78 semester hours toward Bachelors degree.\n",
      "\n",
      "Professional Military Comptroller School, 6wk, 4-98; Managerial Accounting I, 09-98; Interested-Based Bargaining Training for Management,\n",
      "24hrs, 09-01; Auditing Methods and Concepts 09-98; Organizational Leadership, 32hrs, 07-03; Management Development II, 32hrs, 07-03.\n",
      "Certifications\n",
      "Certified Defense Financial Manager, CDFM, May 2005\n",
      "Interests\n",
      "American Society Of Military Comptrollers\n",
      "Additional Information\n",
      "\n",
      "Skills\n",
      "\n",
      "Accounting; General Accounting; Accounts Payable; Program Management.\n",
      "\n",
      "\f\n"
     ]
    }
   ],
   "source": [
    "print(react_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of loaded pages: 2484\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of loaded pages: {len(react_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_documents(documents, chunk_size=500, chunk_overlap=100):\n",
    "    \"\"\"\n",
    "    Splits documents into chunks, optimized for the provided JSON structure.\n",
    "    \"\"\"\n",
    "    processed_documents = []\n",
    "    for doc in documents:\n",
    "        text_content = doc.page_content  # Access the text content directly\n",
    "\n",
    "        # Add double newlines before headings\n",
    "        text_content = re.sub(r'(Summary|Skills|Experience)', r'\\n\\n\\1', text_content)\n",
    "\n",
    "        processed_documents.append(Document(page_content=text_content, metadata=doc.metadata))\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\"] \n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents=processed_documents)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "react_chunks = split_documents(react_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of chunks created: 45566\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of chunks created: {len(react_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_vector_db(chunks, db_name):\n",
    "    \"\"\"\n",
    "    this function uses the open-source embedding model HuggingFaceEmbeddings \n",
    "    to create embeddings and store those in a vector database called FAISS, \n",
    "    which allows for efficient similarity search\n",
    "    \"\"\"\n",
    "    # instantiate embedding model\n",
    "    embedding = HuggingFaceEmbeddings(\n",
    "        model_name='sentence-transformers/all-mpnet-base-v2'\n",
    "    )\n",
    "    # create the vector store \n",
    "    vectorstore = FAISS.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embedding\n",
    "    )\n",
    "    # save vector database locally\n",
    "    vectorstore.save_local(f\"../vector_databases/vector_db_{db_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_embedding_vector_db(chunks=react_chunks, db_name=\"react\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_from_vector_db(vector_db_path):\n",
    "    \"\"\"\n",
    "    this function splits out a retriever object from a local vector database\n",
    "    \"\"\"\n",
    "    # instantiate embedding model\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name='sentence-transformers/all-mpnet-base-v2'\n",
    "    )\n",
    "    react_vectorstore = FAISS.load_local(\n",
    "        folder_path=vector_db_path,\n",
    "        embeddings=embeddings,\n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    retriever = react_vectorstore.as_retriever()\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "react_retriever = retrieve_from_vector_db(\"../vector_databases/vector_db_react\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.vectorstores.base.VectorStoreRetriever"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(react_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_chains(retriever):\n",
    "    \"\"\"\n",
    "    this function connects stuff_documents_chain with retrieval_chain\n",
    "    \"\"\"\n",
    "    stuff_documents_chain = create_stuff_documents_chain(\n",
    "        llm=llm,\n",
    "        prompt=hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
    "    )\n",
    "    retrieval_chain = create_retrieval_chain(\n",
    "        retriever=retriever,\n",
    "        combine_docs_chain=stuff_documents_chain\n",
    "    )\n",
    "    return retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "react_retrieval_chain = connect_chains(react_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = react_retrieval_chain.invoke(\n",
    "    {\"input\": \"Give me the summary of ReAct in 5 sentences\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input', 'context', 'answer'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, here is a summary of ReAct in 5 sentences:\n",
      "\n",
      "ReAct commits people to action with timelines. It transforms complex information into easily understood formats.\n"
     ]
    }
   ],
   "source": [
    "print(output['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
