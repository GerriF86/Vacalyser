{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Verzeichnisstruktur\n",
    "DATA_DIR = \"data\"\n",
    "INPUT_DIR = os.path.join(DATA_DIR, \"input\")\n",
    "PROCESSED_DIR = os.path.join(DATA_DIR, \"processed\")\n",
    "LOG_FILE = os.path.join(DATA_DIR, \"error_log.txt\")\n",
    "\n",
    "# Funktion zur Verarbeitung eines einzelnen PDFs\n",
    "def process_pdf(file_path):\n",
    "    try:\n",
    "        text = extract_text(file_path)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        with open(LOG_FILE, \"a\") as log_file:\n",
    "            log_file.write(f\"Fehler bei {file_path}: {e}\\n\")\n",
    "        return None\n",
    "\n",
    "# Funktion zur Speicherung als JSON\n",
    "def save_as_json(output_file, text, file_path):\n",
    "    data = {\n",
    "        \"file_name\": os.path.basename(file_path),\n",
    "        \"file_path\": file_path,\n",
    "        \"text\": text\n",
    "    }\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "# Funktion zur Verarbeitung aller PDFs in einer rekursiven Verzeichnisstruktur\n",
    "def process_all_pdfs_recursive(input_dir=INPUT_DIR, output_dir=PROCESSED_DIR):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Fehlerlog zur√ºcksetzen\n",
    "    if os.path.exists(LOG_FILE):\n",
    "        os.remove(LOG_FILE)\n",
    "\n",
    "    pdf_files = []\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".pdf\"):\n",
    "                pdf_files.append((root, file))\n",
    "\n",
    "    # Fortschrittsanzeige mit tqdm\n",
    "    for root, file in tqdm(pdf_files, desc=\"PDFs verarbeiten\"):\n",
    "        file_path = os.path.join(root, file)\n",
    "\n",
    "        # Zielpfad basierend auf der Ordnerstruktur\n",
    "        relative_path = os.path.relpath(root, input_dir)\n",
    "        target_dir = os.path.join(output_dir, relative_path)\n",
    "\n",
    "        if not os.path.exists(target_dir):\n",
    "            os.makedirs(target_dir)\n",
    "\n",
    "        # PDF-Inhalt extrahieren\n",
    "        text = process_pdf(file_path)\n",
    "        if text:\n",
    "            # Ergebnis als JSON speichern\n",
    "            output_file = os.path.join(target_dir, file.replace(\".pdf\", \".json\"))\n",
    "            save_as_json(output_file, text, file_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_all_pdfs_recursive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "react_chunks = split_documents(react_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_documents(documents, chunk_size=800, chunk_overlap=80):\n",
    "    \"\"\"\n",
    "    this function splits documents into chunks of given size and overlap\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents=documents)\n",
    "    return chunks"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
